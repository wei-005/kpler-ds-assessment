{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "# 05 — Sequence Forecast (Greedy / Beam) for Task‑A\n# 05 — 任务A多步序列预测（贪心 / Beam）"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "# 项目根路径\n#Project root\nimport sys\nfrom pathlib import Path\nproj_root = Path.cwd()\nif (proj_root.name.lower() == \"notebooks\" or (proj_root/\"utils\").exists() is False) and (proj_root.parent/\"utils\").exists():\n    proj_root = proj_root.parent\nif str(proj_root) not in sys.path:\n    sys.path.append(str(proj_root))\n\nimport numpy as np, pandas as pd, polars as pl, joblib\nfrom utils.config import DATA_DIR, INTERIM_DIR, PROCESSED_DIR\nfrom utils.splits import temporal_split, add_crisis_flag\nfrom utils.candidates import build_origin_next_transitions, global_mf_next, build_pc_coords, build_candidates_for_split\nfrom utils.features import build_ports_attr, compute_port_degree, attach_port_side, build_sample_side, merge_all_features\n\nsamples = pl.read_parquet(PROCESSED_DIR / \"samples_taskA.parquet\")\npc = pl.read_parquet(INTERIM_DIR / \"port_calls.cleaned.parquet\")\ntr = pl.read_csv(DATA_DIR / \"trades.csv\",  try_parse_dates=True)\nvs = pl.read_csv(DATA_DIR / \"vessels.csv\", try_parse_dates=True)\n\ntrain, val, test = temporal_split(samples)\ntrain = add_crisis_flag(train); val = add_crisis_flag(val); test = add_crisis_flag(test)\n\ntrans = build_origin_next_transitions(train)\ng_top = global_mf_next(trans)\npc_coords = build_pc_coords(pc)\n\n# 选择一个测试起点样本\nseed = test.head(1)\nprint(seed)"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "# 载入一个训练好的排序器（LR 或 GBDT 均可）\n#Load a trained ranker (LR or GBDT)\nimport joblib\nlr_path  = PROCESSED_DIR / \"model_taskA_logreg.joblib\"\ngbdt_path= PROCESSED_DIR / \"model_taskA_gbdt.joblib\"\nuse_gbdt = gbdt_path.exists()\n\nif use_gbdt:\n    pack = joblib.load(gbdt_path)\n    clf = pack[\"clf\"]; enc = pack[\"enc\"]\n    num_cols = pack[\"num_cols\"]; cat_cols = pack[\"cat_cols\"]\nelse:\n    clf = joblib.load(lr_path)  # pipeline"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "# 贪心前进一步预测函数\n#Greedy one-step predictor\nfrom utils.features import build_sample_side, merge_all_features, build_ports_attr, compute_port_degree, attach_port_side\n\nports_attr  = build_ports_attr(pc_coords)\nport_degree = compute_port_degree(trans)\ns_side = build_sample_side(samples, pc, vs)\n\ndef rank_topk_for_sample(sample_row: pl.DataFrame, k=5):\n    # 构建候选（不注入真值）\n    cands = build_candidates_for_split(sample_row, trans, pc_coords, add_true_label=False, N=10, M=10, global_top1=g_top)\n    cands = attach_port_side(cands, ports_attr, port_degree)\n    # 标注危机\n    sample_row = add_crisis_flag(sample_row)\n    cands = merge_all_features(cands, s_side, sample_row)\n    # 变成特征矩阵\n    num_cols = [\"dist_km\",\"is_same_region\",\"in_cnt\",\"out_cnt\",\"age\",\n                \"prev_dist_km\",\"last_leg_knots_est\",\"month_sin\",\"month_cos\",\"dow_sin\",\"dow_cos\",\n                \"is_crisis_time\",\"dist_x_crisis\"]\n    cat_cols = [\"origin\",\"candidate\",\"vessel_type\",\"dwt_bucket\",\"product_family_dom\"]\n    import pandas as pd, numpy as np\n    cols = [\"sample_port_call_id\",\"origin\",\"candidate\"] + num_cols + cat_cols\n    for c in num_cols:\n        if c not in cands.columns: cands = cands.with_columns(pl.lit(0.0).alias(c))\n    for c in cat_cols:\n        if c not in cands.columns: cands = cands.with_columns(pl.lit(\"unk\").alias(c))\n    pdf = cands.select(cols).to_pandas()\n\n    if isinstance(clf, object) and hasattr(clf, \"predict_proba\") and hasattr(clf, \"steps\"):  # LR pipeline\n        X = pdf[num_cols + cat_cols]\n        proba = clf.predict_proba(X)[:,1]\n    else:  # GBDT\n        from sklearn.preprocessing import OneHotEncoder\n        enc2 = enc\n        X_num = pdf[num_cols].values\n        X_cat = enc2.transform(pdf[cat_cols])\n        X = np.hstack([X_num, X_cat])\n        proba = clf.predict_proba(X)[:,1]\n\n    pdf[\"score\"] = proba\n    pdf = pdf.sort_values(\"score\", ascending=False)\n    return pdf.head(k)[[\"candidate\",\"score\"]]\n\n# 演示：对 seed 样本做一步预测\ntopk = rank_topk_for_sample(seed, k=5)\nprint(topk)"}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 5}