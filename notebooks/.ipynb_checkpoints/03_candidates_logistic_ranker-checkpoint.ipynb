{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "# 03 — Candidate Recall + Logistic Ranker\n# 03 — 候选召回 + 逻辑回归排序器"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "# 可调整: 项目根路径\n#Adjustable: project root path\nimport sys\nfrom pathlib import Path\nproj_root = Path.cwd()\nif (proj_root.name.lower() == \"notebooks\" or (proj_root/\"utils\").exists() is False) and (proj_root.parent/\"utils\").exists():\n    proj_root = proj_root.parent\nif str(proj_root) not in sys.path:\n    sys.path.append(str(proj_root))\nprint(\"Project root:\", proj_root)\n\n# 统一导入\n#Unified imports\nimport numpy as np, pandas as pd, polars as pl, json, joblib\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import log_loss\n\nfrom utils.config import DATA_DIR, INTERIM_DIR, PROCESSED_DIR\nfrom utils.etl_clean import ensure_interim\nfrom utils.splits import temporal_split, add_crisis_flag\nfrom utils.candidates import build_origin_next_transitions, global_mf_next, build_pc_coords, build_candidates_for_split\nfrom utils.features import build_ports_attr, compute_port_degree, attach_port_side, build_sample_side, merge_all_features\nfrom utils.metrics import eval_topk_mrr"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "# 载入样本与清洗表\n#Load samples and cleaned table\nsamples = pl.read_parquet(PROCESSED_DIR / \"samples_taskA.parquet\")\npc = pl.read_parquet(INTERIM_DIR / \"port_calls.cleaned.parquet\")\ntr = pl.read_csv(DATA_DIR / \"trades.csv\",  try_parse_dates=True)\nvs = pl.read_csv(DATA_DIR / \"vessels.csv\", try_parse_dates=True)\n\ntrain, val, test = temporal_split(samples)\ntrain = add_crisis_flag(train); val = add_crisis_flag(val); test = add_crisis_flag(test)\n\n# 转移、坐标、候选\ntrans = build_origin_next_transitions(train)\ng_top = global_mf_next(trans)\npc_coords = build_pc_coords(pc)\n\ncand_train = build_candidates_for_split(train, trans, pc_coords, add_true_label=True,  N=10, M=10, global_top1=g_top)\ncand_val   = build_candidates_for_split(val,   trans, pc_coords, add_true_label=True,  N=10, M=10, global_top1=g_top)\ncand_test  = build_candidates_for_split(test,  trans, pc_coords, add_true_label=False, N=10, M=10, global_top1=g_top)\n\n# 端口属性/度量 → 端口侧特征\nports_attr  = build_ports_attr(pc_coords)\nport_degree = compute_port_degree(trans)\ncand_train  = attach_port_side(cand_train, ports_attr, port_degree)\ncand_val    = attach_port_side(cand_val,   ports_attr, port_degree)\ncand_test   = attach_port_side(cand_test,  ports_attr, port_degree)\n\n# 样本侧特征\ns_side   = build_sample_side(samples, pc, vs)\ncand_train = merge_all_features(cand_train, s_side, train)\ncand_val   = merge_all_features(cand_val,   s_side, val)\ncand_test  = merge_all_features(cand_test,  s_side, test)\n\nprint(\"cand_train:\", cand_train.shape)"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "# 训练 Logistic Ranker（One-Hot + LR）\n#Train logistic ranker (OHE + LR)\nnum_cols = [\"dist_km\",\"is_same_region\",\"in_cnt\",\"out_cnt\",\"age\",\n            \"prev_dist_km\",\"last_leg_knots_est\",\"month_sin\",\"month_cos\",\"dow_sin\",\"dow_cos\",\n            \"is_crisis_time\",\"dist_x_crisis\"]\ncat_cols = [\"origin\",\"candidate\",\"vessel_type\",\"dwt_bucket\",\"product_family_dom\"]\n\ndef to_xy(df: pl.DataFrame):\n    keep = [\"sample_port_call_id\",\"origin\",\"candidate\",\"label\",\"y\"] + num_cols + cat_cols\n    missing = [c for c in keep if c not in df.columns]\n    for c in missing:\n        if c in num_cols:\n            df = df.with_columns(pl.lit(0.0).alias(c))\n        else:\n            df = df.with_columns(pl.lit(\"unk\").alias(c))\n    pdf = df.select(keep).to_pandas()\n    X = pdf[num_cols + cat_cols]\n    y = pdf[\"y\"].values\n    meta = pdf[[\"sample_port_call_id\",\"origin\",\"candidate\",\"label\"]]\n    return X, y, meta\n\nXtr, ytr, mtr = to_xy(cand_train)\nXva, yva, mva = to_xy(cand_val)\nXte, yte, mte = to_xy(cand_test)\n\npreproc = ColumnTransformer(\n    transformers=[(\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse=True), cat_cols)],\n    remainder=\"passthrough\",\n    sparse_threshold=1.0\n)\nclf = LogisticRegression(max_iter=300, class_weight=\"balanced\", n_jobs=None)\npipe = Pipeline([(\"prep\", preproc), (\"clf\", clf)])\npipe.fit(Xtr, ytr)\n\n# 预测为每个样本的各候选得分，组内排序取 Top-K\ndef rank_predict(pipe, X, meta, ks=(1,3,5)):\n    proba = pipe.predict_proba(X)[:,1]\n    meta2 = meta.copy()\n    meta2[\"score\"] = proba\n    # 按样本聚合排序\n    topk = {}\n    for sid, g in meta2.groupby(\"sample_port_call_id\"):\n        g2 = g.sort_values(\"score\", ascending=False)\n        topk[sid] = g2[\"candidate\"].tolist()\n    truth = []\n    preds = []\n    for sid, g in meta2.groupby(\"sample_port_call_id\"):\n        lab = g[\"label\"].iloc[0]\n        truth.append(lab)\n        preds.append(topk[sid])\n    return preds, truth\n\npreds_val, truth_val = rank_predict(pipe, Xva, mva)\npreds_te,  truth_te  = rank_predict(pipe, Xte, mte)\n\nfrom utils.metrics import eval_topk_mrr\nprint(\"VAL:\", eval_topk_mrr([p[:5] for p in preds_val], truth_val, ks=(1,3,5)))\nprint(\"TEST:\", eval_topk_mrr([p[:5] for p in preds_te],  truth_te,  ks=(1,3,5)))\n\n# 保存模型\nimport joblib, json\noutm = PROCESSED_DIR / \"model_taskA_logreg.joblib\"\njoblib.dump(pipe, outm)\nprint(\"saved:\", outm)"}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 5}