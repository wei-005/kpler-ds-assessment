{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9c933a7",
   "metadata": {},
   "source": [
    "# 03  Candidate Recall + Logistic Ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "465f62a8-87c2-4d23-a2e7-0ea0b2ea5f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adjustable: Add parent directory (which contains utils/) to Python search path\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"..\"))  #  notebooks  sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a062d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Unified imports ===\n",
    "import polars as pl\n",
    "\n",
    "# Display and string cache setup\n",
    "pl.Config.set_tbl_rows(5)\n",
    "pl.Config.set_tbl_cols(10)\n",
    "pl.Config.set_tbl_formatting(\"ASCII_FULL\")\n",
    "\n",
    "# Compatibility: enable global string cache for joins\n",
    "if hasattr(pl, \"enable_string_cache\"):\n",
    "    pl.enable_string_cache()   # Polars ≥ 1.0\n",
    "elif hasattr(pl, \"toggle_string_cache\"):\n",
    "    pl.toggle_string_cache(True)  # legacy\n",
    "\n",
    "# --- Standard imports ---\n",
    "import numpy as np, pandas as pd, json, joblib\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from utils.config import DATA_DIR, INTERIM_DIR, PROCESSED_DIR\n",
    "from utils.etl_clean import ensure_interim\n",
    "from utils.splits import temporal_split, add_crisis_flag\n",
    "from utils.candidates import build_origin_next_transitions, global_mf_next, build_pc_coords, build_candidates_for_split\n",
    "from utils.features import build_ports_attr, compute_port_degree, attach_port_side, build_sample_side, merge_all_features\n",
    "from utils.metrics import eval_topk_mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87d61ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Load samples and cleaned table\n",
    "samples = pl.read_parquet(PROCESSED_DIR / \"samples_taskA.parquet\")\n",
    "pc = pl.read_parquet(INTERIM_DIR / \"port_calls.cleaned.parquet\")\n",
    "tr = pl.read_csv(DATA_DIR / \"trades.csv\",  try_parse_dates=True)\n",
    "vs = pl.read_csv(DATA_DIR / \"vessels.csv\", try_parse_dates=True)\n",
    "\n",
    "train, val, test = temporal_split(samples)\n",
    "train = add_crisis_flag(train); val = add_crisis_flag(val); test = add_crisis_flag(test)\n",
    "\n",
    "trans = build_origin_next_transitions(train)\n",
    "g_top = global_mf_next(trans)\n",
    "pc_coords = build_pc_coords(pc)\n",
    "\n",
    "cand_train = build_candidates_for_split(train, trans, pc_coords, add_true_label=True,  N=10, M=10, global_top1=g_top)\n",
    "cand_val   = build_candidates_for_split(val,   trans, pc_coords, add_true_label=True,  N=10, M=10, global_top1=g_top)\n",
    "cand_test  = build_candidates_for_split(test,  trans, pc_coords, add_true_label=False, N=10, M=10, global_top1=g_top)\n",
    "\n",
    "ports_attr  = build_ports_attr(pc_coords)\n",
    "port_degree = compute_port_degree(trans)\n",
    "cand_train  = attach_port_side(cand_train, ports_attr, port_degree)\n",
    "cand_val    = attach_port_side(cand_val,   ports_attr, port_degree)\n",
    "cand_test   = attach_port_side(cand_test,  ports_attr, port_degree)\n",
    "\n",
    "s_side   = build_sample_side(samples, pc, vs)\n",
    "cand_train = merge_all_features(cand_train, s_side, train)\n",
    "cand_val   = merge_all_features(cand_val,   s_side, val)\n",
    "cand_test  = merge_all_features(cand_test,  s_side, test)\n",
    "\n",
    "print(\"cand_train:\", cand_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24e3093",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Logistic Ranker，One-Hot + LR\n",
    "\n",
    "num_cols = [\"dist_km\",\"is_same_region\",\"in_cnt\",\"out_cnt\",\"age\",\n",
    "            \"prev_dist_km\",\"last_leg_knots_est\",\"month_sin\",\"month_cos\",\"dow_sin\",\"dow_cos\",\n",
    "            \"is_crisis_time\",\"dist_x_crisis\"]\n",
    "cat_cols = [\"origin\",\"candidate\",\"vessel_type\",\"dwt_bucket\",\"product_family_dom\"]\n",
    "\n",
    "def to_xy(df: pl.DataFrame):\n",
    "    keep = [\"sample_port_call_id\",\"origin\",\"candidate\",\"label\",\"y\"] + num_cols + cat_cols\n",
    "    missing = [c for c in keep if c not in df.columns]\n",
    "    for c in missing:\n",
    "        if c in num_cols:\n",
    "            df = df.with_columns(pl.lit(0.0).alias(c))\n",
    "        else:\n",
    "            df = df.with_columns(pl.lit(\"unk\").alias(c))\n",
    "    pdf = df.select(keep).to_pandas()\n",
    "    X = pdf[num_cols + cat_cols]\n",
    "    y = pdf[\"y\"].values\n",
    "    meta = pdf[[\"sample_port_call_id\",\"origin\",\"candidate\",\"label\"]]\n",
    "    return X, y, meta\n",
    "\n",
    "Xtr, ytr, mtr = to_xy(cand_train)\n",
    "Xva, yva, mva = to_xy(cand_val)\n",
    "Xte, yte, mte = to_xy(cand_test)\n",
    "\n",
    "preproc = ColumnTransformer(\n",
    "    transformers=[(\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse=True), cat_cols)],\n",
    "    remainder=\"passthrough\",\n",
    "    sparse_threshold=1.0\n",
    ")\n",
    "clf = LogisticRegression(max_iter=300, class_weight=\"balanced\", n_jobs=None)\n",
    "pipe = Pipeline([(\"prep\", preproc), (\"clf\", clf)])\n",
    "pipe.fit(Xtr, ytr)\n",
    "\n",
    "#  Top-K\n",
    "def rank_predict(pipe, X, meta, ks=(1,3,5)):\n",
    "    proba = pipe.predict_proba(X)[:,1]\n",
    "    meta2 = meta.copy()\n",
    "    meta2[\"score\"] = proba\n",
    "    topk = {}\n",
    "    for sid, g in meta2.groupby(\"sample_port_call_id\"):\n",
    "        g2 = g.sort_values(\"score\", ascending=False)\n",
    "        topk[sid] = g2[\"candidate\"].tolist()\n",
    "    truth = []\n",
    "    preds = []\n",
    "    for sid, g in meta2.groupby(\"sample_port_call_id\"):\n",
    "        lab = g[\"label\"].iloc[0]\n",
    "        truth.append(lab)\n",
    "        preds.append(topk[sid])\n",
    "    return preds, truth\n",
    "\n",
    "preds_val, truth_val = rank_predict(pipe, Xva, mva)\n",
    "preds_te,  truth_te  = rank_predict(pipe, Xte, mte)\n",
    "\n",
    "from utils.metrics import eval_topk_mrr\n",
    "print(\"VAL:\", eval_topk_mrr([p[:5] for p in preds_val], truth_val, ks=(1,3,5)))\n",
    "print(\"TEST:\", eval_topk_mrr([p[:5] for p in preds_te],  truth_te,  ks=(1,3,5)))\n",
    "\n",
    "import joblib, json\n",
    "outm = PROCESSED_DIR / \"model_taskA_logreg.joblib\"\n",
    "joblib.dump(pipe, outm)\n",
    "print(\"saved:\", outm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kpler-ds (Py3.11)",
   "language": "python",
   "name": "kpler-ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
