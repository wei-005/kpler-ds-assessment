{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b4f84de",
   "metadata": {},
   "source": [
    "\n",
    "# 04 · GBDT Ranker for Task‑A (self-contained)\n",
    "\n",
    "This notebook trains a Gradient Boosted Decision Tree **ranker** to predict a vessel's **very next destination** (Task‑A).\n",
    "It **does not rely on `taskA_candidate_pairs.parquet` generated by 03**. Instead, it rebuilds the candidate pairs and features (with caching) and then trains:\n",
    "\n",
    "- **Preferred**: `LightGBMRanker` (`objective=\"lambdarank\"`) if LightGBM is available.\n",
    "- **Fallback**: `HistGradientBoostingClassifier` + one-hot encoding if LightGBM is not available.\n",
    "\n",
    "The pipeline:\n",
    "1. Load `samples_taskA.parquet` (or rebuild from `port_calls.cleaned.parquet` if missing).\n",
    "2. Temporal split: Train / Valid / Test (via `utils.splits.temporal_split`).\n",
    "3. Build candidates per sample (Top‑N historical + Geo‑M + GlobalTop1; cached).\n",
    "4. Attach port-side features (coords/regions/degrees) and sample-side features (vessel attrs, seasonality, last leg speed, etc.).\n",
    "5. **Group-aware downsampling** on train (keep all positives; sample negatives per group).\n",
    "6. Train & evaluate the ranker; export metrics and top‑K predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a38a1ff-911e-4291-b29b-fb0305ceaf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adjustable: Add parent directory (which contains utils/) to Python search path\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"..\"))  #  notebooks  sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81cac66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_DIR     = /Users/wangwei/Documents/Folders/工作/Kpler/data/raw\n",
      "INTERIM_DIR  = /Users/wangwei/Documents/Folders/工作/Kpler/data/interim\n",
      "PROCESSED_DIR= /Users/wangwei/Documents/Folders/工作/Kpler/data/processed\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import numpy as np, pandas as pd, json, joblib, warnings\n",
    "\n",
    "# Use all cores for Polars\n",
    "os.environ[\"POLARS_MAX_THREADS\"] = str(os.cpu_count())\n",
    "\n",
    "# Display setup\n",
    "pl.Config.set_tbl_rows(5)\n",
    "pl.Config.set_tbl_cols(12)\n",
    "\n",
    "# String cache for joins (compat across Polars versions)\n",
    "if hasattr(pl, \"enable_string_cache\"):\n",
    "    pl.enable_string_cache()   # Polars ≥1.0\n",
    "elif hasattr(pl, \"toggle_string_cache\"):\n",
    "    pl.toggle_string_cache(True)\n",
    "\n",
    "# Utils\n",
    "from utils.config import DATA_DIR, INTERIM_DIR, PROCESSED_DIR\n",
    "from utils.etl_clean import ensure_interim\n",
    "from utils.splits import temporal_split, add_crisis_flag\n",
    "from utils.candidates import (\n",
    "    build_origin_next_transitions, global_mf_next, build_pc_coords, build_candidates_for_split\n",
    ")\n",
    "from utils.features import build_ports_attr, compute_port_degree, attach_port_side, build_sample_side, merge_all_features\n",
    "from utils.metrics import eval_topk_mrr\n",
    "\n",
    "print(\"DATA_DIR     =\", DATA_DIR)\n",
    "print(\"INTERIM_DIR  =\", INTERIM_DIR)\n",
    "print(\"PROCESSED_DIR=\", PROCESSED_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e62897cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rows: 260606  Val rows: 56201  Test rows: 21553\n"
     ]
    }
   ],
   "source": [
    "# Load samples (require precomputed by 01/03)\n",
    "samples_path = PROCESSED_DIR / \"samples_taskA.parquet\"\n",
    "assert samples_path.exists(), f\"Missing {samples_path}. Please run notebooks 01/03 first or set KPLER_PROCESSED_DIR.\"\n",
    "samples = pl.read_parquet(samples_path)\n",
    "\n",
    "# Ensure temporal dtype\n",
    "if samples.schema.get(\"call_ts\") == pl.Utf8:\n",
    "    samples = samples.with_columns(pl.col(\"call_ts\").str.strptime(pl.Datetime, strict=False))\n",
    "\n",
    "# Temporal split\n",
    "train, val, test = temporal_split(samples)\n",
    "train = add_crisis_flag(train); val = add_crisis_flag(val); test = add_crisis_flag(test)\n",
    "\n",
    "print(\"Train rows:\", len(train), \" Val rows:\", len(val), \" Test rows:\", len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1026549b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cand_train: (4858920, 9) cand_val: (1048618, 9) cand_test: (393093, 9)\n"
     ]
    }
   ],
   "source": [
    "# Build transitions and coords\n",
    "cleaned = INTERIM_DIR / \"port_calls.cleaned.parquet\"\n",
    "trans = build_origin_next_transitions(train)\n",
    "g_top  = global_mf_next(trans)\n",
    "\n",
    "# Prefer cleaned parquet; if missing and raw also missing, derive coords from cached candidates\n",
    "pc_coords = None\n",
    "if cleaned.exists():\n",
    "    pc = pl.read_parquet(cleaned)\n",
    "    pc_coords = build_pc_coords(pc)\n",
    "else:\n",
    "    # Try to synthesize coordinates from cached candidates if available\n",
    "    cache_train = PROCESSED_DIR / \"cand_train_cached.parquet\"\n",
    "    cache_val   = PROCESSED_DIR / \"cand_val_cached.parquet\"\n",
    "    cc = []\n",
    "    if cache_train.exists(): cc.append(pl.read_parquet(cache_train))\n",
    "    if cache_val.exists():   cc.append(pl.read_parquet(cache_val))\n",
    "    if cc:\n",
    "        cc = pl.concat(cc) if len(cc)>1 else cc[0]\n",
    "        origin_coords = (cc.select([\"origin\",\"lat_o\",\"lon_o\"]).rename({\"origin\":\"destination\",\"lat_o\":\"lat\",\"lon_o\":\"lon\"}))\n",
    "        cand_coords   = (cc.select([\"candidate\",\"lat_c\",\"lon_c\"]).rename({\"candidate\":\"destination\",\"lat_c\":\"lat\",\"lon_c\":\"lon\"}))\n",
    "        pc_coords = pl.concat([origin_coords, cand_coords]).drop_nulls().unique()\n",
    "    else:\n",
    "        # As last resort, rebuild cleaned parquet (requires raw files present)\n",
    "        _ = ensure_interim()\n",
    "        pc = pl.read_parquet(cleaned)\n",
    "        pc_coords = build_pc_coords(pc)\n",
    "\n",
    "# Candidate caches\n",
    "cache_train = PROCESSED_DIR / \"cand_train_cached.parquet\"\n",
    "cache_val   = PROCESSED_DIR / \"cand_val_cached.parquet\"\n",
    "cache_test  = PROCESSED_DIR / \"cand_test_cached.parquet\"\n",
    "\n",
    "if cache_train.exists():\n",
    "    cand_train = pl.read_parquet(cache_train)\n",
    "else:\n",
    "    cand_train = build_candidates_for_split(train, trans, pc_coords, add_true_label=True, N=20, M=20, global_top1=g_top)\n",
    "    cand_train.write_parquet(cache_train)\n",
    "\n",
    "if cache_val.exists():\n",
    "    cand_val = pl.read_parquet(cache_val)\n",
    "else:\n",
    "    cand_val = build_candidates_for_split(val,   trans, pc_coords, add_true_label=True, N=20, M=20, global_top1=g_top)\n",
    "    cand_val.write_parquet(cache_val)\n",
    "\n",
    "if cache_test.exists():\n",
    "    cand_test = pl.read_parquet(cache_test)\n",
    "else:\n",
    "    cand_test = build_candidates_for_split(test,  trans, pc_coords, add_true_label=False, N=20, M=20, global_top1=g_top)\n",
    "    cand_test.write_parquet(cache_test)\n",
    "\n",
    "def assert_no_dup_names(df: pl.DataFrame, name: str):\n",
    "    cols = df.columns\n",
    "    dups = [c for c in set(cols) if cols.count(c) > 1]\n",
    "    assert not dups, f\"{name} has duplicate columns: {dups}\"\n",
    "\n",
    "assert_no_dup_names(cand_train, \"cand_train\")\n",
    "assert_no_dup_names(cand_val,   \"cand_val\")\n",
    "assert_no_dup_names(cand_test,  \"cand_test\")\n",
    "\n",
    "print(\"cand_train:\", cand_train.shape, \"cand_val:\", cand_val.shape, \"cand_test:\", cand_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2076f42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL candidate recall:  100.00%\n",
      "TEST candidate recall: 72.66%\n",
      "Saved candidate pairs to: /Users/wangwei/Documents/Folders/工作/Kpler/data/processed/taskA_candidate_pairs.parquet\n"
     ]
    }
   ],
   "source": [
    "# Port-side attributes & degrees\n",
    "ports_attr  = build_ports_attr(pc_coords)\n",
    "port_degree = compute_port_degree(trans)\n",
    "\n",
    "cand_train  = attach_port_side(cand_train, ports_attr, port_degree)\n",
    "cand_val    = attach_port_side(cand_val,   ports_attr, port_degree)\n",
    "cand_test   = attach_port_side(cand_test,  ports_attr, port_degree)\n",
    "\n",
    "# Sample-side features (vessel attrs, seasonal, last leg speed, etc.)\n",
    "vs = pl.read_csv(DATA_DIR / \"vessels.csv\", try_parse_dates=True) if (DATA_DIR / \"vessels.csv\").exists() else pl.DataFrame({})\n",
    "s_side = build_sample_side(samples, pc, vs)\n",
    "\n",
    "cand_train = merge_all_features(cand_train, s_side, train)\n",
    "cand_val   = merge_all_features(cand_val,   s_side, val)\n",
    "cand_test  = merge_all_features(cand_test,  s_side, test)\n",
    "\n",
    "assert_no_dup_names(cand_train, \"cand_train (post-merge)\")\n",
    "assert_no_dup_names(cand_val,   \"cand_val (post-merge)\")\n",
    "assert_no_dup_names(cand_test,  \"cand_test (post-merge)\")\n",
    "\n",
    "# Quick candidate recall check\n",
    "def candidate_recall(df: pl.DataFrame) -> float:\n",
    "    # 1 if a sample has at least one positive candidate (y==1)\n",
    "    return float(\n",
    "        df.group_by(\"sample_port_call_id\").agg(pl.col(\"y\").max()).select(pl.col(\"y\").mean()).item()\n",
    "    )\n",
    "\n",
    "print(f\"VAL candidate recall:  {candidate_recall(cand_val):.2%}\")\n",
    "print(f\"TEST candidate recall: {candidate_recall(cand_test):.2%}\")\n",
    "\n",
    "# Optional: save combined pairs for reuse by other notebooks\n",
    "pairs_out = PROCESSED_DIR / \"taskA_candidate_pairs.parquet\"\n",
    "all_pairs = (\n",
    "    cand_train.with_columns(pl.lit(\"train\").alias(\"split\"))\n",
    "    .vstack(cand_val.with_columns(pl.lit(\"valid\").alias(\"split\")))\n",
    "    .vstack(cand_test.with_columns(pl.lit(\"test\").alias(\"split\")))\n",
    ")\n",
    "all_pairs.write_parquet(pairs_out)\n",
    "print(\"Saved candidate pairs to:\", pairs_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d2f283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group-aware negative downsampling (keep all positives per sample)\n",
    "def downsample_groupwise(df: pl.DataFrame, neg_per_pos:int=15, seed:int=42) -> pl.DataFrame:\n",
    "    out = []\n",
    "    rng = np.random.default_rng(seed)\n",
    "    for sid, sub in df.group_by(\"sample_port_call_id\", maintain_order=True):\n",
    "        pos = sub.filter(pl.col(\"y\")==1)\n",
    "        neg = sub.filter(pl.col(\"y\")==0)\n",
    "        if len(pos) == 0:\n",
    "            k = min(20, len(neg))\n",
    "            if k > 0:\n",
    "                keep_idx = rng.choice(len(neg), size=k, replace=False)\n",
    "                out.append(neg[keep_idx])\n",
    "            continue\n",
    "        k = min(len(neg), neg_per_pos * len(pos))\n",
    "        if k > 0:\n",
    "            keep_idx = rng.choice(len(neg), size=k, replace=False)\n",
    "            out.append(pl.concat([pos, neg[keep_idx]]))\n",
    "        else:\n",
    "            out.append(pos)\n",
    "    return pl.concat(out) if out else df.head(0)\n",
    "\n",
    "train_keep_cols = [\"sample_port_call_id\",\"origin\",\"candidate\",\"label\",\"y\"]\n",
    "\n",
    "# Numeric features\n",
    "num_cols = [\n",
    "    \"dist_km\",\"is_same_region\",\"in_cnt\",\"out_cnt\",\"age\",\n",
    "    \"prev_dist_km\",\"last_leg_knots_est\",\n",
    "    \"month_sin\",\"month_cos\",\"dow_sin\",\"dow_cos\",\n",
    "    \"is_crisis_time\",\"dist_x_crisis\"\n",
    "]\n",
    "# extra numeric if available\n",
    "extra_num = [c for c in [\n",
    "    \"prior_prob_oc\",\"hist_cnt_oc\",\"prior_prob_oc_vtype\",\"prior_prob_oc_dwt\",\n",
    "    \"prior_prob_oc_laden\",\"prior_prob_oc_pf\",\n",
    "    \"geo_rank_in_sample\",\"log_dist_km\",\"cand_is_waypoint\",\n",
    "    \"in_cnt_cand\",\"out_cnt_cand\"\n",
    "] if c in cand_train.columns]\n",
    "num_cols = num_cols + extra_num\n",
    "\n",
    "# Categorical features\n",
    "cat_cols = [c for c in [\"origin\",\"candidate\",\"vessel_type\",\"dwt_bucket\",\"product_family_dom\"]\n",
    "            if c in cand_train.columns]\n",
    "\n",
    "# Build unique keep cols and backfill missing columns across splits\n",
    "keep_cols = list(dict.fromkeys(train_keep_cols + num_cols + cat_cols))\n",
    "def ensure_cols(df: pl.DataFrame, cols):\n",
    "    for c in cols:\n",
    "        if c not in df.columns:\n",
    "            df = df.with_columns((pl.lit(0.0) if c in num_cols else pl.lit(\"unk\")).alias(c))\n",
    "    return df\n",
    "\n",
    "cand_train = ensure_cols(cand_train, keep_cols)\n",
    "cand_val   = ensure_cols(cand_val,   keep_cols)\n",
    "cand_test  = ensure_cols(cand_test,  keep_cols)\n",
    "\n",
    "# Materialize filtered frames and unique per (sample, candidate)\n",
    "cand_train_u = cand_train.select(keep_cols).unique(subset=[\"sample_port_call_id\",\"candidate\"])\n",
    "cand_val_u   = cand_val.select(keep_cols).unique(subset=[\"sample_port_call_id\",\"candidate\"])\n",
    "cand_test_u  = cand_test.select(keep_cols).unique(subset=[\"sample_port_call_id\",\"candidate\"])\n",
    "\n",
    "# Memory guard: subsample validation/test for demonstration\n",
    "def subsample(df: pl.DataFrame, n:int=100_000, seed:int=42) -> pl.DataFrame:\n",
    "    return df if len(df) <= n else df.sample(n=n, seed=seed)\n",
    "cand_val_u  = subsample(cand_val_u,  n=100_000)\n",
    "cand_test_u = subsample(cand_test_u, n=100_000)\n",
    "\n",
    "# Optional pre-sample training set to control memory (similar to 03)\n",
    "if len(cand_train_u) > 700_000:\n",
    "    cand_train_u = cand_train_u.sample(n=700_000, seed=42)\n",
    "cand_train_ds = downsample_groupwise(cand_train_u, neg_per_pos=12, seed=42)\n",
    "\n",
    "print(\"Train (unique):\", cand_train_u.shape, \" -> Downsampled:\", cand_train_ds.shape)\n",
    "print(\"Val   (unique):\", cand_val_u.shape)\n",
    "print(\"Test  (unique):\", cand_test_u.shape)\n",
    "\n",
    "# Disable LightGBM in this run to avoid heavy memory/OMP issues; use logistic fallback\n",
    "use_lgbm = False\n",
    "print(\"LightGBM disabled for this run; using logistic fallback.\")\n",
    "\n",
    "def prep_for_lgb(df_pl: pl.DataFrame):\n",
    "    df_pd = df_pl.select(keep_cols).to_pandas()\n",
    "    for c in cat_cols:\n",
    "        df_pd[c] = df_pd[c].astype(\"category\")\n",
    "    for c in num_cols:\n",
    "        if c in df_pd.columns:\n",
    "            df_pd[c] = pd.to_numeric(df_pd[c], errors=\"coerce\").replace([np.inf, -np.inf], np.nan)\n",
    "    X = df_pd[num_cols + cat_cols]\n",
    "    y = df_pd[\"y\"].astype(int).values\n",
    "    group_sizes = df_pd.groupby(\"sample_port_call_id\")[\"candidate\"].size().values.tolist()\n",
    "    meta = df_pd[[\"sample_port_call_id\",\"origin\",\"candidate\",\"label\"]]\n",
    "    return X, y, group_sizes, meta\n",
    "\n",
    "if use_lgbm:\n",
    "    Xtr, ytr, gtr, mtr = prep_for_lgb(cand_train_ds)\n",
    "    Xva, yva, gva, mva = prep_for_lgb(cand_val_u)\n",
    "    Xte, yte, gte, mte = prep_for_lgb(cand_test_u)\n",
    "\n",
    "    ranker = lgb.LGBMRanker(\n",
    "        objective=\"lambdarank\",\n",
    "        metric=\"map\",\n",
    "        learning_rate=0.05,\n",
    "        n_estimators=800,\n",
    "        num_leaves=63,\n",
    "        max_depth=-1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    ranker.fit(\n",
    "        Xtr, ytr, group=gtr,\n",
    "        eval_set=[(Xva, yva)],\n",
    "        eval_group=[gva],\n",
    "        eval_at=[1,3,5],\n",
    "        categorical_feature=cat_cols,\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=150, verbose=False),\n",
    "            lgb.log_evaluation(50)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    def rank_predict_ranker(model, X, meta):\n",
    "        s = model.predict(X, num_iteration=model.best_iteration_)\n",
    "        meta2 = meta.copy()\n",
    "        meta2[\"score\"] = s\n",
    "        preds, truth = [], []\n",
    "        for sid, g in meta2.groupby(\"sample_port_call_id\"):\n",
    "            g2 = g.sort_values(\"score\", ascending=False)\n",
    "            preds.append(g2[\"candidate\"].tolist())\n",
    "            truth.append(g2[\"label\"].iloc[0])\n",
    "        return preds, truth\n",
    "\n",
    "    preds_val, truth_val = rank_predict_ranker(ranker, Xva, mva)\n",
    "    preds_te,  truth_te  = rank_predict_ranker(ranker, Xte, mte)\n",
    "\n",
    "    m_val  = eval_topk_mrr([p[:5] for p in preds_val], truth_val, ks=(1,3,5))\n",
    "    m_test = eval_topk_mrr([p[:5] for p in preds_te],  truth_te,  ks=(1,3,5))\n",
    "\n",
    "    print(\"VAL:\",  m_val)\n",
    "    print(\"TEST:\", m_test)\n",
    "\n",
    "    # Save model\n",
    "    outm = PROCESSED_DIR / \"model_taskA_lgbm_ranker.txt\"\n",
    "    ranker.booster_.save_model(outm)\n",
    "    with open(PROCESSED_DIR / \"metrics_gbdt.json\", \"w\") as f:\n",
    "        json.dump({\"val\": m_val, \"test\": m_test}, f, indent=2)\n",
    "    print(\"Saved model:\", outm)\n",
    "\n",
    "else:\n",
    "    # Fallback — Logistic with sparse OHE to reduce memory\n",
    "    from sklearn.compose import ColumnTransformer\n",
    "    from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "    def to_xy(df_pl: pl.DataFrame):\n",
    "        df2 = df_pl.select(keep_cols).unique(subset=[\"sample_port_call_id\",\"candidate\"])\n",
    "        pdf = df2.to_pandas()\n",
    "        X = pdf[num_cols + cat_cols]\n",
    "        y = pdf[\"y\"].astype(int).values\n",
    "        meta = pdf[[\"sample_port_call_id\",\"origin\",\"candidate\",\"label\"]]\n",
    "        return X, y, meta\n",
    "\n",
    "    Xtr, ytr, mtr = to_xy(cand_train_ds)\n",
    "    Xva, yva, mva = to_xy(cand_val_u)\n",
    "    Xte, yte, mte = to_xy(cand_test_u)\n",
    "\n",
    "    numeric = Pipeline([(\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "                        (\"std\", StandardScaler())])\n",
    "    preproc = ColumnTransformer(\n",
    "        transformers=[(\"num\", numeric, num_cols),\n",
    "                      (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse=True), cat_cols)],\n",
    "        remainder=\"drop\"\n",
    "    )\n",
    "\n",
    "    clf = LogisticRegression(max_iter=200, solver=\"saga\", n_jobs=-1, verbose=0)\n",
    "    pipe = Pipeline([(\"prep\", preproc), (\"clf\", clf)])\n",
    "    pipe.fit(Xtr, ytr)\n",
    "\n",
    "    def rank_predict_clf(pipe, X, meta):\n",
    "        if hasattr(pipe.named_steps['clf'], 'predict_proba'):\n",
    "            proba = pipe.predict_proba(X)[:, 1]\n",
    "        else:\n",
    "            proba = pipe.decision_function(X)\n",
    "        meta2 = meta.copy()\n",
    "        meta2[\"score\"] = proba\n",
    "        preds, truth = [], []\n",
    "        for sid, g in meta2.groupby(\"sample_port_call_id\"):\n",
    "            g2 = g.sort_values(\"score\", ascending=False)\n",
    "            preds.append(g2[\"candidate\"].tolist())\n",
    "            truth.append(g2[\"label\"].iloc[0])\n",
    "        return preds, truth\n",
    "\n",
    "    preds_val, truth_val = rank_predict_clf(pipe, Xva, mva)\n",
    "    preds_te,  truth_te  = rank_predict_clf(pipe, Xte, mte)\n",
    "\n",
    "    m_val  = eval_topk_mrr([p[:5] for p in preds_val], truth_val, ks=(1,3,5))\n",
    "    m_test = eval_topk_mrr([p[:5] for p in preds_te],  truth_te,  ks=(1,3,5))\n",
    "\n",
    "    print(\"VAL:\",  m_val)\n",
    "    print(\"TEST:\", m_test)\n",
    "\n",
    "    outm = PROCESSED_DIR / \"model_taskA_hgb_ranker.joblib\"\n",
    "    joblib.dump(pipe, outm)\n",
    "    with open(PROCESSED_DIR / \"metrics_gbdt.json\", \"w\") as f:\n",
    "        json.dump({\"val\": m_val, \"test\": m_test}, f, indent=2)\n",
    "    print(\"Saved model:\", outm)\n",
    "\n",
    "# Dump Top‑5\n",
    "def dump_topk(meta, preds, split_name, k=5):\n",
    "    rows = []\n",
    "    # meta can be pandas DataFrame from prep\n",
    "    sids = meta[\"sample_port_call_id\"].unique()\n",
    "    for sid, plist in zip(sids, preds):\n",
    "        rows.append({\"sample_port_call_id\": sid, \"pred_topk\": plist[:k]})\n",
    "    outp = PROCESSED_DIR / f\"rank_top{str(k)}_{split_name}.parquet\"\n",
    "    pl.DataFrame(rows).write_parquet(outp)\n",
    "    print(\"Saved:\", outp)\n",
    "\n",
    "dump_topk(mva, preds_val, \"val\", k=5)\n",
    "dump_topk(mte, preds_te,  \"test\", k=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kpler-ds (Py3.11)",
   "language": "python",
   "name": "kpler-ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
