{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "# 04 — Candidate Recall + GBDT Ranker\n# 04 — 候选召回 + GBDT 排序器"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "# 项目根路径\n#Project root\nimport sys\nfrom pathlib import Path\nproj_root = Path.cwd()\nif (proj_root.name.lower() == \"notebooks\" or (proj_root/\"utils\").exists() is False) and (proj_root.parent/\"utils\").exists():\n    proj_root = proj_root.parent\nif str(proj_root) not in sys.path:\n    sys.path.append(str(proj_root))\nprint(\"Project root:\", proj_root)\n\n# 统一导入\n#Unified imports\nimport numpy as np, pandas as pd, polars as pl, json, joblib\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import HistGradientBoostingClassifier\n\nfrom utils.config import DATA_DIR, INTERIM_DIR, PROCESSED_DIR\nfrom utils.etl_clean import ensure_interim\nfrom utils.splits import temporal_split, add_crisis_flag\nfrom utils.candidates import build_origin_next_transitions, global_mf_next, build_pc_coords, build_candidates_for_split\nfrom utils.features import build_ports_attr, compute_port_degree, attach_port_side, build_sample_side, merge_all_features\nfrom utils.metrics import eval_topk_mrr"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "# 载入样本与清洗表\nsamples = pl.read_parquet(PROCESSED_DIR / \"samples_taskA.parquet\")\npc = pl.read_parquet(INTERIM_DIR / \"port_calls.cleaned.parquet\")\ntr = pl.read_csv(DATA_DIR / \"trades.csv\",  try_parse_dates=True)\nvs = pl.read_csv(DATA_DIR / \"vessels.csv\", try_parse_dates=True)\n\ntrain, val, test = temporal_split(samples)\ntrain = add_crisis_flag(train); val = add_crisis_flag(val); test = add_crisis_flag(test)\n\ntrans = build_origin_next_transitions(train)\ng_top = global_mf_next(trans)\npc_coords = build_pc_coords(pc)\n\ncand_train = build_candidates_for_split(train, trans, pc_coords, add_true_label=True,  N=10, M=10, global_top1=g_top)\ncand_val   = build_candidates_for_split(val,   trans, pc_coords, add_true_label=True,  N=10, M=10, global_top1=g_top)\ncand_test  = build_candidates_for_split(test,  trans, pc_coords, add_true_label=False, N=10, M=10, global_top1=g_top)\n\nports_attr  = build_ports_attr(pc_coords)\nport_degree = compute_port_degree(trans)\ncand_train  = attach_port_side(cand_train, ports_attr, port_degree)\ncand_val    = attach_port_side(cand_val,   ports_attr, port_degree)\ncand_test   = attach_port_side(cand_test,  ports_attr, port_degree)\n\ns_side   = build_sample_side(samples, pc, vs)\ncand_train = merge_all_features(cand_train, s_side, train)\ncand_val   = merge_all_features(cand_val,   s_side, val)\ncand_test  = merge_all_features(cand_test,  s_side, test)"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "# 训练 GBDT 排序器（HGB）\nnum_cols = [\"dist_km\",\"is_same_region\",\"in_cnt\",\"out_cnt\",\"age\",\n            \"prev_dist_km\",\"last_leg_knots_est\",\"month_sin\",\"month_cos\",\"dow_sin\",\"dow_cos\",\n            \"is_crisis_time\",\"dist_x_crisis\"]\ncat_cols = [\"origin\",\"candidate\",\"vessel_type\",\"dwt_bucket\",\"product_family_dom\"]\n\ndef to_xy(df: pl.DataFrame):\n    keep = [\"sample_port_call_id\",\"origin\",\"candidate\",\"label\",\"y\"] + num_cols + cat_cols\n    for c in num_cols:\n        if c not in df.columns: df = df.with_columns(pl.lit(0.0).alias(c))\n    for c in cat_cols:\n        if c not in df.columns: df = df.with_columns(pl.lit(\"unk\").alias(c))\n    pdf = df.select(keep).to_pandas()\n    X_num = pdf[num_cols].values\n    # 将类别独热编码为 dense（HGB 不吃稀疏）\n    enc = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n    X_cat = enc.fit_transform(pdf[cat_cols])\n    X = np.hstack([X_num, X_cat])\n    y = pdf[\"y\"].values\n    meta = pdf[[\"sample_port_call_id\",\"origin\",\"candidate\",\"label\"]]\n    return X, y, meta, enc\n\nXtr, ytr, mtr, enc = to_xy(cand_train)\n# 确保 val/test 使用同一个 encoder\ndef to_xy_with_enc(df: pl.DataFrame, enc):\n    keep = [\"sample_port_call_id\",\"origin\",\"candidate\",\"label\",\"y\"] + num_cols + cat_cols\n    for c in num_cols:\n        if c not in df.columns: df = df.with_columns(pl.lit(0.0).alias(c))\n    for c in cat_cols:\n        if c not in df.columns: df = df.with_columns(pl.lit(\"unk\").alias(c))\n    pdf = df.select(keep).to_pandas()\n    X_num = pdf[num_cols].values\n    X_cat = enc.transform(pdf[cat_cols])\n    X = np.hstack([X_num, X_cat])\n    y = pdf[\"y\"].values\n    meta = pdf[[\"sample_port_call_id\",\"origin\",\"candidate\",\"label\"]]\n    return X, y, meta\n\nXva, yva, mva = to_xy_with_enc(cand_val, enc)\nXte, yte, mte = to_xy_with_enc(cand_test, enc)\n\nclf = HistGradientBoostingClassifier(max_depth=8, learning_rate=0.08, max_iter=300)\nclf.fit(Xtr, ytr)\n\ndef rank_predict_hgb(clf, X, meta, ks=(1,3,5)):\n    proba = clf.predict_proba(X)[:,1]\n    meta2 = meta.copy()\n    meta2[\"score\"] = proba\n    topk = {}\n    for sid, g in meta2.groupby(\"sample_port_call_id\"):\n        g2 = g.sort_values(\"score\", ascending=False)\n        topk[sid] = g2[\"candidate\"].tolist()\n    truth, preds = [], []\n    for sid, g in meta2.groupby(\"sample_port_call_id\"):\n        truth.append(g[\"label\"].iloc[0])\n        preds.append(topk[sid])\n    return preds, truth\n\nfrom utils.metrics import eval_topk_mrr\npreds_val, truth_val = rank_predict_hgb(clf, Xva, mva)\npreds_te,  truth_te  = rank_predict_hgb(clf, Xte, mte)\nprint(\"VAL:\", eval_topk_mrr([p[:5] for p in preds_val], truth_val, ks=(1,3,5)))\nprint(\"TEST:\", eval_topk_mrr([p[:5] for p in preds_te],  truth_te,  ks=(1,3,5)))\n\n# 保存模型和 encoder\nimport joblib\njoblib.dump({\"clf\":clf, \"enc\":enc, \"num_cols\":num_cols, \"cat_cols\":cat_cols}, PROCESSED_DIR / \"model_taskA_gbdt.joblib\")\nprint(\"saved:\", PROCESSED_DIR / \"model_taskA_gbdt.joblib\")"}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 5}