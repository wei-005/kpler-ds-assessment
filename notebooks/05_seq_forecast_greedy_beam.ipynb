{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46cb5175",
   "metadata": {},
   "source": [
    "# 05 — Sequence Forecast (Greedy / Beam) for Task‑A\n",
    "# 05 — 任务A多步序列预测（贪心 / Beam）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5acfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 项目根路径\n",
    "#Project root\n",
    "import sys\n",
    "from pathlib import Path\n",
    "proj_root = Path.cwd()\n",
    "if (proj_root.name.lower() == \"notebooks\" or (proj_root/\"utils\").exists() is False) and (proj_root.parent/\"utils\").exists():\n",
    "    proj_root = proj_root.parent\n",
    "if str(proj_root) not in sys.path:\n",
    "    sys.path.append(str(proj_root))\n",
    "\n",
    "import numpy as np, pandas as pd, polars as pl, joblib\n",
    "from utils.config import DATA_DIR, INTERIM_DIR, PROCESSED_DIR\n",
    "from utils.splits import temporal_split, add_crisis_flag\n",
    "from utils.candidates import build_origin_next_transitions, global_mf_next, build_pc_coords, build_candidates_for_split\n",
    "from utils.features import build_ports_attr, compute_port_degree, attach_port_side, build_sample_side, merge_all_features\n",
    "\n",
    "samples = pl.read_parquet(PROCESSED_DIR / \"samples_taskA.parquet\")\n",
    "pc = pl.read_parquet(INTERIM_DIR / \"port_calls.cleaned.parquet\")\n",
    "tr = pl.read_csv(DATA_DIR / \"trades.csv\",  try_parse_dates=True)\n",
    "vs = pl.read_csv(DATA_DIR / \"vessels.csv\", try_parse_dates=True)\n",
    "\n",
    "train, val, test = temporal_split(samples)\n",
    "train = add_crisis_flag(train); val = add_crisis_flag(val); test = add_crisis_flag(test)\n",
    "\n",
    "trans = build_origin_next_transitions(train)\n",
    "g_top = global_mf_next(trans)\n",
    "pc_coords = build_pc_coords(pc)\n",
    "\n",
    "# 选择一个测试起点样本\n",
    "seed = test.head(1)\n",
    "print(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8720d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 载入一个训练好的排序器（LR 或 GBDT 均可）\n",
    "#Load a trained ranker (LR or GBDT)\n",
    "import joblib\n",
    "lr_path  = PROCESSED_DIR / \"model_taskA_logreg.joblib\"\n",
    "gbdt_path= PROCESSED_DIR / \"model_taskA_gbdt.joblib\"\n",
    "use_gbdt = gbdt_path.exists()\n",
    "\n",
    "if use_gbdt:\n",
    "    pack = joblib.load(gbdt_path)\n",
    "    clf = pack[\"clf\"]; enc = pack[\"enc\"]\n",
    "    num_cols = pack[\"num_cols\"]; cat_cols = pack[\"cat_cols\"]\n",
    "else:\n",
    "    clf = joblib.load(lr_path)  # pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f089f93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 贪心前进一步预测函数\n",
    "#Greedy one-step predictor\n",
    "from utils.features import build_sample_side, merge_all_features, build_ports_attr, compute_port_degree, attach_port_side\n",
    "\n",
    "ports_attr  = build_ports_attr(pc_coords)\n",
    "port_degree = compute_port_degree(trans)\n",
    "s_side = build_sample_side(samples, pc, vs)\n",
    "\n",
    "def rank_topk_for_sample(sample_row: pl.DataFrame, k=5):\n",
    "    # 构建候选（不注入真值）\n",
    "    cands = build_candidates_for_split(sample_row, trans, pc_coords, add_true_label=False, N=10, M=10, global_top1=g_top)\n",
    "    cands = attach_port_side(cands, ports_attr, port_degree)\n",
    "    # 标注危机\n",
    "    sample_row = add_crisis_flag(sample_row)\n",
    "    cands = merge_all_features(cands, s_side, sample_row)\n",
    "    # 变成特征矩阵\n",
    "    num_cols = [\"dist_km\",\"is_same_region\",\"in_cnt\",\"out_cnt\",\"age\",\n",
    "                \"prev_dist_km\",\"last_leg_knots_est\",\"month_sin\",\"month_cos\",\"dow_sin\",\"dow_cos\",\n",
    "                \"is_crisis_time\",\"dist_x_crisis\"]\n",
    "    cat_cols = [\"origin\",\"candidate\",\"vessel_type\",\"dwt_bucket\",\"product_family_dom\"]\n",
    "    import pandas as pd, numpy as np\n",
    "    cols = [\"sample_port_call_id\",\"origin\",\"candidate\"] + num_cols + cat_cols\n",
    "    for c in num_cols:\n",
    "        if c not in cands.columns: cands = cands.with_columns(pl.lit(0.0).alias(c))\n",
    "    for c in cat_cols:\n",
    "        if c not in cands.columns: cands = cands.with_columns(pl.lit(\"unk\").alias(c))\n",
    "    pdf = cands.select(cols).to_pandas()\n",
    "\n",
    "    if isinstance(clf, object) and hasattr(clf, \"predict_proba\") and hasattr(clf, \"steps\"):  # LR pipeline\n",
    "        X = pdf[num_cols + cat_cols]\n",
    "        proba = clf.predict_proba(X)[:,1]\n",
    "    else:  # GBDT\n",
    "        from sklearn.preprocessing import OneHotEncoder\n",
    "        enc2 = enc\n",
    "        X_num = pdf[num_cols].values\n",
    "        X_cat = enc2.transform(pdf[cat_cols])\n",
    "        X = np.hstack([X_num, X_cat])\n",
    "        proba = clf.predict_proba(X)[:,1]\n",
    "\n",
    "    pdf[\"score\"] = proba\n",
    "    pdf = pdf.sort_values(\"score\", ascending=False)\n",
    "    return pdf.head(k)[[\"candidate\",\"score\"]]\n",
    "\n",
    "# 演示：对 seed 样本做一步预测\n",
    "topk = rank_topk_for_sample(seed, k=5)\n",
    "print(topk)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kpler-ds (Py3.11)",
   "language": "python",
   "name": "kpler-ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
