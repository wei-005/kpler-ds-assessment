{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9c933a7",
   "metadata": {},
   "source": [
    "# 03 — Candidate Recall + Logistic Ranker\n",
    "# 03 — 候选召回 + 逻辑回归排序器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "465f62a8-87c2-4d23-a2e7-0ea0b2ea5f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可调整: 将上一级目录（包含 utils/）加入 Python 搜索路径\n",
    "#Adjustable: Add parent directory (which contains utils/) to Python search path\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"..\"))  # 把 notebooks 的上一级加入 sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a062d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统一导入\n",
    "#Unified imports\n",
    "import numpy as np, pandas as pd, polars as pl, json, joblib\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from utils.config import DATA_DIR, INTERIM_DIR, PROCESSED_DIR\n",
    "from utils.etl_clean import ensure_interim\n",
    "from utils.splits import temporal_split, add_crisis_flag\n",
    "from utils.candidates import build_origin_next_transitions, global_mf_next, build_pc_coords, build_candidates_for_split\n",
    "from utils.features import build_ports_attr, compute_port_degree, attach_port_side, build_sample_side, merge_all_features\n",
    "from utils.metrics import eval_topk_mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a87d61ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file or directory (os error 2): /Users/wangwei/Documents/Folders/工作/Kpler/data/processed/samples_taskA.parquet\n\nThis error occurred with the following context stack:\n\t[1] 'parquet scan'\n\t[2] 'sink'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:3\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/kpler-ds/lib/python3.11/site-packages/polars/_utils/deprecation.py:128\u001b[0m, in \u001b[0;36mdeprecate_renamed_parameter.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(function)\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    125\u001b[0m     _rename_keyword_argument(\n\u001b[1;32m    126\u001b[0m         old_name, new_name, kwargs, function\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m, version\n\u001b[1;32m    127\u001b[0m     )\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/kpler-ds/lib/python3.11/site-packages/polars/_utils/deprecation.py:128\u001b[0m, in \u001b[0;36mdeprecate_renamed_parameter.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(function)\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    125\u001b[0m     _rename_keyword_argument(\n\u001b[1;32m    126\u001b[0m         old_name, new_name, kwargs, function\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m, version\n\u001b[1;32m    127\u001b[0m     )\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/kpler-ds/lib/python3.11/site-packages/polars/io/parquet/functions.py:289\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(source, columns, n_rows, row_index_name, row_index_offset, parallel, use_statistics, hive_partitioning, glob, schema, hive_schema, try_parse_hive_dates, rechunk, low_memory, storage_options, credential_provider, retries, use_pyarrow, pyarrow_options, memory_map, include_file_paths, missing_columns, allow_missing_columns)\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    287\u001b[0m         lf \u001b[38;5;241m=\u001b[39m lf\u001b[38;5;241m.\u001b[39mselect(columns)\n\u001b[0;32m--> 289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/kpler-ds/lib/python3.11/site-packages/polars/_utils/deprecation.py:97\u001b[0m, in \u001b[0;36mdeprecate_streaming_parameter.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min-memory\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstreaming\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 97\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/kpler-ds/lib/python3.11/site-packages/polars/lazyframe/opt_flags.py:330\u001b[0m, in \u001b[0;36mforward_old_opt_flags.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m         optflags \u001b[38;5;241m=\u001b[39m cb(optflags, kwargs\u001b[38;5;241m.\u001b[39mpop(key))  \u001b[38;5;66;03m# type: ignore[no-untyped-call,unused-ignore]\u001b[39;00m\n\u001b[1;32m    329\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizations\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m optflags\n\u001b[0;32m--> 330\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/kpler-ds/lib/python3.11/site-packages/polars/lazyframe/frame.py:2407\u001b[0m, in \u001b[0;36mLazyFrame.collect\u001b[0;34m(self, type_coercion, predicate_pushdown, projection_pushdown, simplify_expression, slice_pushdown, comm_subplan_elim, comm_subexpr_elim, cluster_with_columns, collapse_joins, no_optimization, engine, background, optimizations, **_kwargs)\u001b[0m\n\u001b[1;32m   2405\u001b[0m \u001b[38;5;66;03m# Only for testing purposes\u001b[39;00m\n\u001b[1;32m   2406\u001b[0m callback \u001b[38;5;241m=\u001b[39m _kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost_opt_callback\u001b[39m\u001b[38;5;124m\"\u001b[39m, callback)\n\u001b[0;32m-> 2407\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap_df(\u001b[43mldf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No such file or directory (os error 2): /Users/wangwei/Documents/Folders/工作/Kpler/data/processed/samples_taskA.parquet\n\nThis error occurred with the following context stack:\n\t[1] 'parquet scan'\n\t[2] 'sink'\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 载入样本与清洗表\n",
    "#Load samples and cleaned table\n",
    "samples = pl.read_parquet(PROCESSED_DIR / \"samples_taskA.parquet\")\n",
    "pc = pl.read_parquet(INTERIM_DIR / \"port_calls.cleaned.parquet\")\n",
    "tr = pl.read_csv(DATA_DIR / \"trades.csv\",  try_parse_dates=True)\n",
    "vs = pl.read_csv(DATA_DIR / \"vessels.csv\", try_parse_dates=True)\n",
    "\n",
    "train, val, test = temporal_split(samples)\n",
    "train = add_crisis_flag(train); val = add_crisis_flag(val); test = add_crisis_flag(test)\n",
    "\n",
    "# 转移、坐标、候选\n",
    "trans = build_origin_next_transitions(train)\n",
    "g_top = global_mf_next(trans)\n",
    "pc_coords = build_pc_coords(pc)\n",
    "\n",
    "cand_train = build_candidates_for_split(train, trans, pc_coords, add_true_label=True,  N=10, M=10, global_top1=g_top)\n",
    "cand_val   = build_candidates_for_split(val,   trans, pc_coords, add_true_label=True,  N=10, M=10, global_top1=g_top)\n",
    "cand_test  = build_candidates_for_split(test,  trans, pc_coords, add_true_label=False, N=10, M=10, global_top1=g_top)\n",
    "\n",
    "# 端口属性/度量 → 端口侧特征\n",
    "ports_attr  = build_ports_attr(pc_coords)\n",
    "port_degree = compute_port_degree(trans)\n",
    "cand_train  = attach_port_side(cand_train, ports_attr, port_degree)\n",
    "cand_val    = attach_port_side(cand_val,   ports_attr, port_degree)\n",
    "cand_test   = attach_port_side(cand_test,  ports_attr, port_degree)\n",
    "\n",
    "# 样本侧特征\n",
    "s_side   = build_sample_side(samples, pc, vs)\n",
    "cand_train = merge_all_features(cand_train, s_side, train)\n",
    "cand_val   = merge_all_features(cand_val,   s_side, val)\n",
    "cand_test  = merge_all_features(cand_test,  s_side, test)\n",
    "\n",
    "print(\"cand_train:\", cand_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a24e3093",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cand_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m     meta \u001b[38;5;241m=\u001b[39m pdf[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_port_call_id\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morigin\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcandidate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X, y, meta\n\u001b[0;32m---> 22\u001b[0m Xtr, ytr, mtr \u001b[38;5;241m=\u001b[39m to_xy(\u001b[43mcand_train\u001b[49m)\n\u001b[1;32m     23\u001b[0m Xva, yva, mva \u001b[38;5;241m=\u001b[39m to_xy(cand_val)\n\u001b[1;32m     24\u001b[0m Xte, yte, mte \u001b[38;5;241m=\u001b[39m to_xy(cand_test)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cand_train' is not defined"
     ]
    }
   ],
   "source": [
    "# 训练 Logistic Ranker（One-Hot + LR）\n",
    "#Train logistic ranker (OHE + LR)\n",
    "num_cols = [\"dist_km\",\"is_same_region\",\"in_cnt\",\"out_cnt\",\"age\",\n",
    "            \"prev_dist_km\",\"last_leg_knots_est\",\"month_sin\",\"month_cos\",\"dow_sin\",\"dow_cos\",\n",
    "            \"is_crisis_time\",\"dist_x_crisis\"]\n",
    "cat_cols = [\"origin\",\"candidate\",\"vessel_type\",\"dwt_bucket\",\"product_family_dom\"]\n",
    "\n",
    "def to_xy(df: pl.DataFrame):\n",
    "    keep = [\"sample_port_call_id\",\"origin\",\"candidate\",\"label\",\"y\"] + num_cols + cat_cols\n",
    "    missing = [c for c in keep if c not in df.columns]\n",
    "    for c in missing:\n",
    "        if c in num_cols:\n",
    "            df = df.with_columns(pl.lit(0.0).alias(c))\n",
    "        else:\n",
    "            df = df.with_columns(pl.lit(\"unk\").alias(c))\n",
    "    pdf = df.select(keep).to_pandas()\n",
    "    X = pdf[num_cols + cat_cols]\n",
    "    y = pdf[\"y\"].values\n",
    "    meta = pdf[[\"sample_port_call_id\",\"origin\",\"candidate\",\"label\"]]\n",
    "    return X, y, meta\n",
    "\n",
    "Xtr, ytr, mtr = to_xy(cand_train)\n",
    "Xva, yva, mva = to_xy(cand_val)\n",
    "Xte, yte, mte = to_xy(cand_test)\n",
    "\n",
    "preproc = ColumnTransformer(\n",
    "    transformers=[(\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse=True), cat_cols)],\n",
    "    remainder=\"passthrough\",\n",
    "    sparse_threshold=1.0\n",
    ")\n",
    "clf = LogisticRegression(max_iter=300, class_weight=\"balanced\", n_jobs=None)\n",
    "pipe = Pipeline([(\"prep\", preproc), (\"clf\", clf)])\n",
    "pipe.fit(Xtr, ytr)\n",
    "\n",
    "# 预测为每个样本的各候选得分，组内排序取 Top-K\n",
    "def rank_predict(pipe, X, meta, ks=(1,3,5)):\n",
    "    proba = pipe.predict_proba(X)[:,1]\n",
    "    meta2 = meta.copy()\n",
    "    meta2[\"score\"] = proba\n",
    "    # 按样本聚合排序\n",
    "    topk = {}\n",
    "    for sid, g in meta2.groupby(\"sample_port_call_id\"):\n",
    "        g2 = g.sort_values(\"score\", ascending=False)\n",
    "        topk[sid] = g2[\"candidate\"].tolist()\n",
    "    truth = []\n",
    "    preds = []\n",
    "    for sid, g in meta2.groupby(\"sample_port_call_id\"):\n",
    "        lab = g[\"label\"].iloc[0]\n",
    "        truth.append(lab)\n",
    "        preds.append(topk[sid])\n",
    "    return preds, truth\n",
    "\n",
    "preds_val, truth_val = rank_predict(pipe, Xva, mva)\n",
    "preds_te,  truth_te  = rank_predict(pipe, Xte, mte)\n",
    "\n",
    "from utils.metrics import eval_topk_mrr\n",
    "print(\"VAL:\", eval_topk_mrr([p[:5] for p in preds_val], truth_val, ks=(1,3,5)))\n",
    "print(\"TEST:\", eval_topk_mrr([p[:5] for p in preds_te],  truth_te,  ks=(1,3,5)))\n",
    "\n",
    "# 保存模型\n",
    "import joblib, json\n",
    "outm = PROCESSED_DIR / \"model_taskA_logreg.joblib\"\n",
    "joblib.dump(pipe, outm)\n",
    "print(\"saved:\", outm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kpler-ds (Py3.11)",
   "language": "python",
   "name": "kpler-ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
