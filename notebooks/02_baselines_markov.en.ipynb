{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ec1f888",
   "metadata": {},
   "source": [
    "# 02  Baselines: Global-MF & Conditional Markov\n",
    "# 02   &  Markov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d747838-1dca-4d0d-8db2-25fde8c91d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adjustable: Add parent directory (which contains utils/) to Python search path\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"..\"))  #  notebooks  sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dff2bac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, numpy as np, pandas as pd, polars as pl\n",
    "from utils.config import DATA_DIR, INTERIM_DIR, PROCESSED_DIR\n",
    "from utils.etl_clean import ensure_interim, build_samples_taskA\n",
    "from utils.splits import temporal_split, add_crisis_flag\n",
    "from utils.candidates import build_origin_next_transitions, global_mf_next\n",
    "from utils.metrics import eval_topk_mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c683f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes: (260606, 16) (56201, 16) (21553, 16)\n"
     ]
    }
   ],
   "source": [
    "#Load samples; rebuild if missing\n",
    "s_path = PROCESSED_DIR / \"samples_taskA.parquet\"\n",
    "if not s_path.exists():\n",
    "    pc = ensure_interim()\n",
    "    tr = pl.read_csv(DATA_DIR / \"trades.csv\",  try_parse_dates=True)\n",
    "    vs = pl.read_csv(DATA_DIR / \"vessels.csv\", try_parse_dates=True)\n",
    "    _ = build_samples_taskA(pc, tr, vs)\n",
    "\n",
    "samples = pl.read_parquet(s_path)\n",
    "train, val, test = temporal_split(samples)\n",
    "train = add_crisis_flag(train); val = add_crisis_flag(val); test = add_crisis_flag(test)\n",
    "print(\"shapes:\", train.shape, val.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "960d8c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOBAL_TOP1: Singapore\n"
     ]
    }
   ],
   "source": [
    "#Build transitions & global most-frequent\n",
    "trans = build_origin_next_transitions(train)\n",
    "g_top = global_mf_next(trans)\n",
    "print(\"GLOBAL_TOP1:\", g_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29fcbaf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val  Global-MF: {'hits@1': 0.03674311844984965, 'hits@3': 0.03674311844984965, 'hits@5': 0.03674311844984965, 'mrr': 0.03674311844984965}\n",
      "Val  Markov-1 : {'hits@1': 0.03674311844984965, 'hits@3': 0.03674311844984965, 'hits@5': 0.03674311844984965, 'mrr': 0.03674311844984965}\n",
      "Test Global-MF: {'hits@1': 0.038324131211432286, 'hits@3': 0.038324131211432286, 'hits@5': 0.038324131211432286, 'mrr': 0.038324131211432286}\n",
      "Test Markov-1 : {'hits@1': 0.038324131211432286, 'hits@3': 0.038324131211432286, 'hits@5': 0.038324131211432286, 'mrr': 0.038324131211432286}\n",
      "saved: /Users/wangwei/Documents/Folders/工作/Kpler/data/processed/baseline_taskA_metrics.json\n"
     ]
    }
   ],
   "source": [
    "#Evaluation: Val/Test\n",
    "def predict_top1_gmf(n):\n",
    "    return [[g_top] for _ in range(n)]\n",
    "\n",
    "def topk_by_markov(split_df: pl.DataFrame, K=5):\n",
    "    #  Top-K \n",
    "    topk_map = {}\n",
    "    for origin, sub in trans.group_by(\"destination\", maintain_order=True):\n",
    "        arr = sub.sort(\"cnt\", descending=True)[\"next_call_name\"].to_list()[:K]\n",
    "        topk_map[origin] = arr\n",
    "    preds = [topk_map.get(o, [g_top]) for o in split_df[\"destination\"].to_list()]\n",
    "    return preds\n",
    "\n",
    "val_truth = val[\"next_call_name\"].to_list()\n",
    "test_truth= test[\"next_call_name\"].to_list()\n",
    "\n",
    "pred0_val  = predict_top1_gmf(len(val_truth))\n",
    "pred0_test = predict_top1_gmf(len(test_truth))\n",
    "res0_val   = eval_topk_mrr(pred0_val,  val_truth, ks=(1,3,5))\n",
    "res0_test  = eval_topk_mrr(pred0_test, test_truth, ks=(1,3,5))\n",
    "\n",
    "pred1_val  = topk_by_markov(val, K=5)\n",
    "pred1_test = topk_by_markov(test, K=5)\n",
    "res1_val   = eval_topk_mrr(pred1_val,  val_truth, ks=(1,3,5))\n",
    "res1_test  = eval_topk_mrr(pred1_test, test_truth, ks=(1,3,5))\n",
    "\n",
    "print(\"Val  Global-MF:\", res0_val)\n",
    "print(\"Val  Markov-1 :\", res1_val)\n",
    "print(\"Test Global-MF:\", res0_test)\n",
    "print(\"Test Markov-1 :\", res1_test)\n",
    "\n",
    "out = PROCESSED_DIR / \"baseline_taskA_metrics.json\"\n",
    "import json\n",
    "out.write_text(json.dumps({\"val_gmf\":res0_val,\"val_mkv\":res1_val,\"test_gmf\":res0_test,\"test_mkv\":res1_test}, indent=2), encoding=\"utf-8\")\n",
    "print(\"saved:\", out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kpler-ds (Py3.11)",
   "language": "python",
   "name": "kpler-ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
